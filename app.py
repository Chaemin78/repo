import os
import time
import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig
from safetensors.torch import load_file
from openai import OpenAI


# ==============================
# 0) ì„¤ì •
# ==============================
st.set_page_config(page_title="Solar Chat Room", page_icon="â˜€ï¸", layout="centered")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "kcelectra-toxic-best")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# í† í¬ë‚˜ì´ì €ëŠ” ê¸°ì¡´ì²˜ëŸ¼ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=True)

# 1) configë¡œ "ë¹ˆ" ëª¨ë¸ ìƒì„± (ì•„ì§ ê°€ì¤‘ì¹˜ ì—†ìŒ, ê·¸ëƒ¥ ì¼ë°˜ nn.Module)
config = AutoConfig.from_pretrained(MODEL_DIR)
clf_model = AutoModelForSequenceClassification.from_config(config)

# 2) safetensorsì—ì„œ state_dict ì§ì ‘ ë¡œë“œ
state_path = os.path.join(MODEL_DIR, "model.safetensors")
state_dict = load_file(state_path)  # <- safetensors.torch.load_file

missing, unexpected = clf_model.load_state_dict(state_dict, strict=False)
print("missing keys:", missing)
print("unexpected keys:", unexpected)

# 3) ì´ì œ ì§„ì§œ í…ì„œê°€ ì˜¬ë¼ê°„ ìƒíƒœì´ë‹ˆ .to() í•´ë„ meta ì´ìŠˆ ì—†ìŒ
clf_model = clf_model.to(DEVICE).eval()


from dotenv import load_dotenv
load_dotenv()

SOLAR_API_KEY = os.getenv("UPSTAGE_API_KEY")
if SOLAR_API_KEY is None:
    raise ValueError("í™˜ê²½ë³€ìˆ˜ UPSTAGE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .envì— ì„¤ì •í•˜ì„¸ìš”.")

client = OpenAI(api_key=SOLAR_API_KEY, base_url="https://api.upstage.ai/v1")

# ë°ëª¨ íŒŒë¼ë¯¸í„°
BOT_NAMES = ["ë¯¼ìˆ˜", "ì§€ì•„"] 
USER_NAME = "ë‚˜"
TOXIC_THRESHOLD = 0.50


# ==============================
# 1) ìœ í‹¸ í•¨ìˆ˜
# ==============================
@torch.inference_mode()
def classify_toxicity(text: str):
    # ëª¨ë¸ì´ ì˜¬ë¼ê°„ ì²« íŒŒë¼ë¯¸í„°ì˜ deviceë¡œ ë³´ëƒ„ (device_map=auto ëŒ€ë¹„)
    target_device = next(clf_model.parameters()).device
    enc = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=128
    ).to(target_device)

    logits = clf_model(**enc).logits
    probs = torch.softmax(logits, dim=-1)[0].detach().cpu().numpy()
    return float(probs[0]), float(probs[1])


def solar_reply(history_messages, speaker_name: str) -> str:
    transcript = "\n".join([f"{m['name']}: {m['text']}" for m in history_messages[-8:]])


    system_msg = {
    "role": "system",
    "content": (
        f"ë„ˆëŠ” 10ëŒ€ ì²­ì†Œë…„ {speaker_name}ì´ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ì•¼ í•´.\n\n"
        "ê·œì¹™:\n"
        "- ë‹µë³€ì—ëŠ” ì˜¤ì§ í•œ ë¬¸ì¥ë§Œ ì¶œë ¥í•  ê²ƒ. (ìµœëŒ€ 40ì ë‚´ì™¸)\n"
        "- ì„¤ëª…, í•´ì„, ë©”íƒ€ì½”ë©˜íŠ¸, ì˜ˆì‹œ, ìƒê° ê³¼ì •, ë²ˆì—­, ìš”ì•½ ë“±ì„ ì ˆëŒ€ ì“°ì§€ ë§ ê²ƒ.\n"
        "- ê´„í˜¸() ì•ˆì— í•´ì„¤ ì“°ì§€ ë§ ê²ƒ.\n"
        "- <think>, </think> ê°™ì€ íƒœê·¸ë¥¼ í¬í•¨í•œ ì–´ë–¤ íƒœê·¸ë„ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ.\n"
        "- ë³¸ì¸ ì´ë¦„/ì¸ì‚¬/ìê¸°ì†Œê°œ/ì„œëª…/ì´ëª¨ì§€/í•´ì‹œíƒœê·¸/ë”°ì˜´í‘œë„ ì ˆëŒ€ ê¸ˆì§€.\n"
        "- 'ë¯¼ìˆ˜:' ê°™ì€ í™”ì í‘œê¸° ê¸ˆì§€. ë‚´ìš©ë§Œ ì¶œë ¥.\n"
        "- ì• ì‚¬ëŒ ë§ì„ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ì§€ ë§ ê²ƒ.\n"
        "- ë°˜ë§ë¡œ, ë°”ë¡œ ì§ì „ ì‚¬ëŒì˜ ë§ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” í•œ ë§ˆë””ë§Œ ì¶œë ¥í•  ê²ƒ.\n"
    )
}


    user_msg = {
    "role": "user",
    "content": (
        (transcript + "\n") if transcript else "" 
    ) + f"{speaker_name}ì˜ ë‹¤ìŒ í•œ ë§ˆë””ë§Œ ì‘ì„±í•´. "
        "ì´ë¦„ ì—†ì´ ë‚´ìš©ë§Œ, í•œ ë¬¸ì¥ë§Œ ì¶œë ¥í•´."
}


    stop_list = [f"\n{n}:" for n in [speaker_name, "ë‚˜", "ë¯¼ìˆ˜", "ì§€ì•„", "í˜„ìš°"]]

    resp = client.chat.completions.create(
        model="solar-pro2",
        messages=[system_msg, user_msg],
        stream=False,
        max_tokens=80,
        temperature=0.3,
        top_p=0.9,
        stop=stop_list,
    )
    return resp.choices[0].message.content.strip()


# ==============================
# 2) ì„¸ì…˜ ìƒíƒœ
# ==============================
if "chat" not in st.session_state:
    st.session_state.chat = []
if "init_done" not in st.session_state:
    st.session_state.init_done = False

# ==============================
# 4) ëŒ€í™” ì˜ì—­
# ==============================
st.title("â˜€ï¸ ì²­ì§„ê¸° ì±„íŒ…ë°©")

chat_placeholder = st.empty()  # ì±„íŒ…ì„ ë Œë”ë§í•  ìë¦¬

def render_all_messages():
    with chat_placeholder.container():
        for msg in st.session_state.chat:
            who = USER_NAME if msg["role"] == "user" else msg["name"]
            st.markdown(f"**{who}** Â· *{msg['ts']}*  \n{msg['text']}")

# ì²˜ìŒ ë¡œë“œ ì‹œ í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ë Œë”
render_all_messages()
st.divider()


# ==============================
# 5) ì…ë ¥ & ë¡œì§
# ==============================

user_text = st.text_input("ë‚´ ë©”ì‹œì§€", placeholder="ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
send = st.button("ë³´ë‚´ê¸°", type="primary")

if send and user_text.strip():
    user_text = user_text.strip()

    # 1) ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ + ë°”ë¡œ ë Œë”
    user_msg = {
        "role": "user",
        "name": USER_NAME,
        "text": user_text,
        "ts": time.strftime("%H:%M:%S"),
    }
    st.session_state.chat.append(user_msg)
    render_all_messages()

    # 2) ì•…ì„± íŒì •
    p_tox, p_clean = classify_toxicity(user_text)
    # ë””ë²„ê¹…ìš©ìœ¼ë¡œ ë³´ê³  ì‹¶ìœ¼ë©´:
    # st.write("p_tox:", p_tox, "p_clean:", p_clean)

    if p_tox >= TOXIC_THRESHOLD:
        st.error("ğŸš¨ ê²½ê³ : ì•…ì„± ë°œí™” ê°ì§€ â€” ì¹œêµ¬ì™€ ëŒ€í™”í•  ë•ŒëŠ” ë°”ë¥´ê³  ê³ ìš´ ë§ì„ ì‚¬ìš©í•´ìš”.")
        # ì—¬ê¸°ì„œ ë°”ë¡œ ì¢…ë£Œ
        st.stop()

    # 3) ì •ìƒì¼ ë•Œ: ë´‡ 2ëª… ìˆœì°¨ ì‘ë‹µ + 2ì´ˆ í…€
    for name in BOT_NAMES:
        with st.spinner("ë©”ì„¸ì§€ ì‘ì„± ì¤‘..."):
            reply = solar_reply(st.session_state.chat, name)
            bot_msg = {
                "role": "bot",
                "name": name,
                "text": reply,
                "ts": time.strftime("%H:%M:%S"),
            }
            st.session_state.chat.append(bot_msg)
            render_all_messages()   # ìƒˆ ë©”ì‹œì§€ê¹Œì§€ í¬í•¨í•´ì„œ ë‹¤ì‹œ ê·¸ë¦¼
        time.sleep(2)                # ê° ë´‡ ì‚¬ì´ 2ì´ˆ í…€
